{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from train.basic_train import BasicTrain\n",
    "from metrics.metrics import Metrics\n",
    "from utils.reporter import Reporter\n",
    "from utils.misc import timeit\n",
    "from utils.average_meter import FPSMeter\n",
    "\n",
    "calcAvgDepth = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\seq\\train_seq\\\n",
      "c:\\seq\\val_seq\\\n"
     ]
    }
   ],
   "source": [
    "train_seq_folder = 'c:\\\\seq\\\\train_seq\\\\'\n",
    "val_seq_folder = 'c:\\\\seq\\\\val_seq\\\\'\n",
    "print(train_seq_folder)\n",
    "print(val_seq_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\seq\\\\train_seq\\\\annotated_man_chicken_dance_3_cam_labeled.h5', 'c:\\\\seq\\\\train_seq\\\\annotated_woman_hand_signals_3_cam_labeled.h5', 'c:\\\\seq\\\\train_seq\\\\annotated_woman_wash_window_3_cam_labeled.h5']\n"
     ]
    }
   ],
   "source": [
    "train_seq_files = []\n",
    "for (dirpath, dirnames, filenames) in os.walk(train_seq_folder):\n",
    "    train_seq_files.extend(os.path.join(dirpath, x) for x in filenames)\n",
    "print(train_seq_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\seq\\\\val_seq\\\\annotated_man_chicken_dance_3_cam_labeled.h5']\n"
     ]
    }
   ],
   "source": [
    "val_seq_files = []\n",
    "for (dirpath, dirnames, filenames) in os.walk(val_seq_folder):\n",
    "    val_seq_files.extend(os.path.join(dirpath, x) for x in filenames)\n",
    "print(val_seq_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (calcAvgDepth):\n",
    "    avg_depth = 0\n",
    "    for train_seq_name in train_seq_files:\n",
    "        train_seq = h5py.File(train_seq_name, \"r\")\n",
    "        num_cameras = train_seq['INFO']['NUM_CAMERAS'].value[0]\n",
    "        num_frames = train_seq['INFO']['COUNT'].value[0]\n",
    "        for frame_idx in range(num_frames):\n",
    "            for cam_idx in range(num_cameras):\n",
    "                depth_path = 'FRAME{:04d}/RAW/CAM{:d}/Z'.format(frame_idx, cam_idx)\n",
    "                depth_image = train_seq[depth_path].value\n",
    "                depth_mask = depth_image > 0\n",
    "                avg_depth += np.average(depth_image, weights = depth_mask)\n",
    "\n",
    "        avg_depth /= num_frames * num_cameras\n",
    "        train_seq.close()\n",
    "\n",
    "    print (avg_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filenames = []\n",
    "for train_seq_name in train_seq_files:\n",
    "    train_seq = h5py.File(train_seq_name, \"r\")\n",
    "    num_cameras = train_seq['INFO']['NUM_CAMERAS'].value[0]\n",
    "    num_frames = train_seq['INFO']['COUNT'].value[0]\n",
    "    train_seq.close()\n",
    "    for frame_idx in range(num_frames):\n",
    "        for cam_idx in range(num_cameras):\n",
    "            train_filename_str = train_seq_name + '__' + 'FRAME{:04d}/RAW/CAM{:d}/'.format(frame_idx, cam_idx)\n",
    "            train_filenames.append(train_filename_str)\n",
    "\n",
    "val_filenames = []\n",
    "for val_seq_name in val_seq_files:\n",
    "    val_seq = h5py.File(val_seq_name, \"r\")\n",
    "    num_cameras = val_seq['INFO']['NUM_CAMERAS'].value[0]\n",
    "    num_frames = val_seq['INFO']['COUNT'].value[0]\n",
    "    val_seq.close()\n",
    "    for frame_idx in range(num_frames):\n",
    "        for cam_idx in range(num_cameras):\n",
    "            val_filename_str = val_seq_name + '__' + 'FRAME{:04d}/RAW/CAM{:d}/'.format(frame_idx, cam_idx)\n",
    "            val_filenames.append(val_filename_str)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_hdf5_func(filename, label):\n",
    "    filename_decoded = filename.decode(\"utf-8\")\n",
    "    print(filename_decoded)\n",
    "    h5_file_name, group_name = filename_decoded.split('__')\n",
    "    h5_file = h5py.File(h5_file_name, \"r\")\n",
    "    #print(group_name)\n",
    "    \n",
    "    # Read depth image\n",
    "    depth_image_path = group_name + 'Z'\n",
    "    depth_image = h5_file[depth_image_path].value\n",
    "    #depth_image_scaled = np.array(depth_image, copy=False)\n",
    "    #depth_image_scaled.clip(MIN_DEPTH, MAX_DEPTH, out=depth_image_scaled)\n",
    "    #depth_image_scaled -= MIN_DEPTH\n",
    "    #np.floor_divide(depth_image_scaled, (MAX_DEPTH - MIN_DEPTH + 1) / 256,\n",
    "    #                out=depth_image_scaled, casting='unsafe')\n",
    "    \n",
    "    #depth_image_scaled = depth_image_scaled.astype(np.uint8)\n",
    "    \n",
    "    # Read labels\n",
    "    label_image_path = group_name + 'LABEL'\n",
    "    label_image = h5_file[label_image_path].value\n",
    "    h5_file.close()\n",
    "    return depth_image, label_image\n",
    "\n",
    "val_labels = [0]*len(val_filenames)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_filenames, val_labels))\n",
    "val_dataset = val_dataset.shuffle(buffer_size=10000)\n",
    "val_dataset = val_dataset.map(\n",
    "    lambda filename, label: tuple(tf.py_func(\n",
    "        _read_hdf5_func, [filename, label], [tf.int16, tf.uint8])), num_parallel_calls=1)\n",
    "\n",
    "\n",
    "#val_dataset = dataset.batch(10)\n",
    "#val_dataset = dataset.repeat()\n",
    "#val_dataset = dataset.prefetch(1)\n",
    "\n",
    "\n",
    "\n",
    "train_labels = [0]*len(train_filenames)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_filenames, train_labels))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=10000)\n",
    "train_dataset = train_dataset.map(\n",
    "    lambda filename, label: tuple(tf.py_func(\n",
    "        _read_hdf5_func, [filename, label], [tf.int16, tf.uint8])), num_parallel_calls=1)\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.batch(1)\n",
    "train_dataset = train_dataset.repeat()\n",
    "train_dataset = train_dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\seq\\train_seq\\annotated_man_chicken_dance_3_cam_labeled.h5__FRAME0129/RAW/CAM2/\n",
      "c:\\seq\\train_seq\\annotated_woman_hand_signals_3_cam_labeled.h5__FRAME0229/RAW/CAM2/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]]], dtype=int16),\n",
       " array([[[46, 46, 46, ..., 46, 46, 46],\n",
       "         [46, 46, 46, ..., 46, 46, 46],\n",
       "         [46, 46, 46, ..., 46, 46, 46],\n",
       "         ...,\n",
       "         [46, 46, 46, ..., 46, 46, 46],\n",
       "         [46, 46, 46, ..., 46, 46, 46],\n",
       "         [46, 46, 46, ..., 46, 46, 46]]], dtype=uint8)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterator = train_dataset.make_one_shot_iterator()\n",
    "next_depth, next_label = iterator.get_next()\n",
    "\n",
    "sess.run([next_depth, next_label])\n",
    "#sess.run(next_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202.97058823529412\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Trainer class to train Segmentation models\n",
    "\"\"\"\n",
    "\n",
    "from tqdm import tqdm\n",
    "from utils.augmentation import flip_randomly_left_right_image_with_annotation, \\\n",
    "    scale_randomly_image_with_annotation_with_fixed_size_output\n",
    "import scipy.misc as misc\n",
    "\n",
    "\n",
    "class TrainPsy(BasicTrain):\n",
    "    \"\"\"\n",
    "    Trainer class\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, args, sess, train_model, test_model):\n",
    "        \"\"\"\n",
    "        Call the constructor of the base class\n",
    "        init summaries\n",
    "        init loading data\n",
    "        :param args:\n",
    "        :param sess:\n",
    "        :param model:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        super().__init__(args, sess, train_model, test_model)\n",
    "        ##################################################################################\n",
    "        # Init summaries\n",
    "\n",
    "        # Summary variables\n",
    "        self.scalar_summary_tags = ['mean_iou_on_val',\n",
    "                                    'train-loss-per-epoch', 'val-loss-per-epoch',\n",
    "                                    'train-acc-per-epoch', 'val-acc-per-epoch']\n",
    "        self.images_summary_tags = [\n",
    "            ('train_prediction_sample', [None, self.params.img_height, self.params.img_width * 2, 3]),\n",
    "            ('val_prediction_sample', [None, self.params.img_height, self.params.img_width * 2, 3])]\n",
    "        self.summary_tags = []\n",
    "        self.summary_placeholders = {}\n",
    "        self.summary_ops = {}\n",
    "        # init summaries and it's operators\n",
    "        self.init_summaries()\n",
    "        # Create summary writer\n",
    "        self.summary_writer = tf.summary.FileWriter(self.args.summary_dir, self.sess.graph)\n",
    "        ##################################################################################\n",
    "        # Init metrics class\n",
    "        self.metrics = Metrics(self.args.num_classes)\n",
    "        # Init reporter class\n",
    "        if self.args.mode == 'train' or 'overfit':\n",
    "            self.reporter = Reporter(self.args.out_dir + 'report_train.json', self.args)\n",
    "        elif self.args.mode == 'test':\n",
    "            self.reporter = Reporter(self.args.out_dir + 'report_test.json', self.args)\n",
    "            ##################################################################################\n",
    "\n",
    "    def init_summaries(self):\n",
    "        \"\"\"\n",
    "        Create the summary part of the graph\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        with tf.variable_scope('train-summary-per-epoch'):\n",
    "            for tag in self.scalar_summary_tags:\n",
    "                self.summary_tags += tag\n",
    "                self.summary_placeholders[tag] = tf.placeholder('float32', None, name=tag)\n",
    "                self.summary_ops[tag] = tf.summary.scalar(tag, self.summary_placeholders[tag])\n",
    "            for tag, shape in self.images_summary_tags:\n",
    "                self.summary_tags += tag\n",
    "                self.summary_placeholders[tag] = tf.placeholder('float32', shape, name=tag)\n",
    "                self.summary_ops[tag] = tf.summary.image(tag, self.summary_placeholders[tag], max_outputs=10)\n",
    "\n",
    "    def add_summary(self, step, summaries_dict=None, summaries_merged=None):\n",
    "        \"\"\"\n",
    "        Add the summaries to tensorboard\n",
    "        :param step:\n",
    "        :param summaries_dict:\n",
    "        :param summaries_merged:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if summaries_dict is not None:\n",
    "            summary_list = self.sess.run([self.summary_ops[tag] for tag in summaries_dict.keys()],\n",
    "                                         {self.summary_placeholders[tag]: value for tag, value in\n",
    "                                          summaries_dict.items()})\n",
    "            for summary in summary_list:\n",
    "                self.summary_writer.add_summary(summary, step)\n",
    "        if summaries_merged is not None:\n",
    "            self.summary_writer.add_summary(summaries_merged, step)\n",
    "\n",
    "    def train(self):\n",
    "        print(\"Training mode will begin NOW ..\")\n",
    "        # curr_lr= self.model.args.learning_rate\n",
    "        for cur_epoch in range(self.model.global_epoch_tensor.eval(self.sess) + 1, self.args.num_epochs + 1, 1):\n",
    "\n",
    "            tt = tqdm(self.generator(), total=self.num_iterations_training_per_epoch,\n",
    "                      desc=\"epoch-\" + str(cur_epoch) + \"-\")\n",
    "            # init acc and loss lists\n",
    "            loss_list = []\n",
    "            acc_list = []\n",
    "            for _ in tt:\n",
    "                # get the cur_it for the summary\n",
    "                cur_it = self.model.global_step_tensor.eval(self.sess)\n",
    "\n",
    "                # Feed this variables to the network\n",
    "                feed_dict = {self.model.x_pl: x_batch,\n",
    "                             self.model.y_pl: y_batch,\n",
    "                             self.model.is_training: True\n",
    "                             #self.model.curr_learning_rate:curr_lr\n",
    "                             }\n",
    "\n",
    "                # run the feed_forward\n",
    "                _, loss, acc, summaries_merged = self.sess.run(\n",
    "                    [self.model.train_op, self.model.loss, self.model.accuracy, \n",
    "                     self.model.merged_summaries],\n",
    "                    feed_dict=feed_dict)\n",
    "                # log loss and acc\n",
    "                loss_list += [loss]\n",
    "                acc_list += [acc]\n",
    "                \n",
    "                # Update the Global step\n",
    "                self.model.global_step_assign_op.eval(session=self.sess,\n",
    "                                                      feed_dict={self.model.global_step_input: cur_it + 1})\n",
    "\n",
    "            total_loss = np.mean(loss_list)\n",
    "            total_acc = np.mean(acc_list)\n",
    "            \n",
    "            # summarize\n",
    "            summaries_dict = dict()\n",
    "            summaries_dict['train-loss-per-epoch'] = total_loss\n",
    "            summaries_dict['train-acc-per-epoch'] = total_acc\n",
    "\n",
    "            if self.args.data_mode != 'experiment_v2':\n",
    "                summaries_dict['train_prediction_sample'] = segmented_imgs\n",
    "            # self.add_summary(cur_it, summaries_dict=summaries_dict, summaries_merged=summaries_merged)\n",
    "\n",
    "            # report\n",
    "            self.reporter.report_experiment_statistics('train-acc', 'epoch-' + str(cur_epoch), str(total_acc))\n",
    "            self.reporter.report_experiment_statistics('train-loss', 'epoch-' + str(cur_epoch), str(total_loss))\n",
    "            self.reporter.finalize()\n",
    "\n",
    "            # Update the Cur Epoch tensor\n",
    "            # it is the last thing because if it is interrupted it repeat this\n",
    "            self.model.global_epoch_assign_op.eval(session=self.sess,\n",
    "                                                   feed_dict={self.model.global_epoch_input: cur_epoch + 1})\n",
    "\n",
    "            # print in console\n",
    "            tt.close()\n",
    "            print(\"epoch-\" + str(cur_epoch) + \"-\" + \"loss:\" + str(total_loss) + \"-\" + \" acc:\" + str(total_acc)[\n",
    "                                                                                                :6])\n",
    "\n",
    "            # Save the current checkpoint\n",
    "            if cur_epoch % self.args.save_every == 0:\n",
    "                self.save_model()\n",
    "\n",
    "            # Test the model on validation\n",
    "            if cur_epoch % self.args.test_every == 0:\n",
    "                self.test_per_epoch(step=self.model.global_step_tensor.eval(self.sess),\n",
    "                                    epoch=self.model.global_epoch_tensor.eval(self.sess))\n",
    "\n",
    "        print(\"Training Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def test_per_epoch(self, step, epoch):\n",
    "        print(\"Validation at step:\" + str(step) + \" at epoch:\" + str(epoch) + \" ..\")\n",
    "\n",
    "        # init tqdm and get the epoch value\n",
    "        tt = tqdm(range(self.num_iterations_validation_per_epoch), total=self.num_iterations_validation_per_epoch,\n",
    "                  desc=\"Val-epoch-\" + str(epoch) + \"-\")\n",
    "\n",
    "        # init acc and loss lists\n",
    "        loss_list = []\n",
    "        acc_list = []\n",
    "        inf_list = []\n",
    "\n",
    "        # reset metrics\n",
    "        self.metrics.reset()\n",
    "\n",
    "        # get the maximum iou to compare with and save the best model\n",
    "        max_iou = self.model.best_iou_tensor.eval(self.sess)\n",
    "\n",
    "        # loop by the number of iterations\n",
    "        for _ in tt:\n",
    "            # load minibatches\n",
    "            x_batch = self.val_data['X'][idx:idx + self.args.batch_size]\n",
    "            y_batch = self.val_data['Y'][idx:idx + self.args.batch_size]\n",
    "            if self.args.data_mode == 'experiment_v2':\n",
    "                y_batch_large = self.val_data['Y_large'][idx:idx + self.args.batch_size]\n",
    "\n",
    "            # update idx of minibatch\n",
    "            idx += self.args.batch_size\n",
    "\n",
    "            # Feed this variables to the network\n",
    "            feed_dict = {self.model.x_pl: x_batch,\n",
    "                         self.model.y_pl: y_batch,\n",
    "                         self.model.is_training: False\n",
    "                         }\n",
    "\n",
    "            start = time.time()\n",
    "            # run the feed_forward\n",
    "\n",
    "            out_argmax, loss, acc, summaries_merged = self.sess.run(\n",
    "                [self.model.out_argmax, self.model.loss, self.model.accuracy, self.model.merged_summaries],\n",
    "                feed_dict=feed_dict)\n",
    "\n",
    "            end = time.time()\n",
    "            # log loss and acc\n",
    "            loss_list += [loss]\n",
    "            acc_list += [acc]\n",
    "            inf_list += [end - start]\n",
    "\n",
    "            # log metrics\n",
    "            self.metrics.update_metrics_batch(out_argmax, y_batch)\n",
    "\n",
    "\n",
    "        # mean over batches\n",
    "        total_acc = np.mean(acc_list)\n",
    "        mean_iou = self.metrics.compute_final_metrics(self.num_iterations_validation_per_epoch)\n",
    "        mean_iou_arr = self.metrics.iou\n",
    "        mean_inference = str(np.mean(inf_list)) + '-seconds'\n",
    "        # summarize\n",
    "        summaries_dict = dict()\n",
    "        summaries_dict['val-acc-per-epoch'] = total_acc\n",
    "        summaries_dict['mean_iou_on_val'] = mean_iou\n",
    "\n",
    "        # report\n",
    "        self.reporter.report_experiment_statistics('validation-acc', 'epoch-' + str(epoch), str(total_acc))\n",
    "        self.reporter.report_experiment_statistics('avg_inference_time_on_validation', 'epoch-' + str(epoch),\n",
    "                                                   str(mean_inference))\n",
    "        self.reporter.report_experiment_validation_iou('epoch-' + str(epoch), str(mean_iou), mean_iou_arr)\n",
    "        self.reporter.finalize()\n",
    "\n",
    "        # print in console\n",
    "        tt.close()\n",
    "        print(\"Val-epoch-\" + str(epoch) + \"-\" +\n",
    "              \"acc:\" + str(total_acc)[:6] + \"-mean_iou:\" + str(mean_iou))\n",
    "        print(\"Last_max_iou: \" + str(max_iou))\n",
    "        if mean_iou > max_iou:\n",
    "            print(\"This validation got a new best iou. so we will save this one\")\n",
    "            # save the best model\n",
    "            self.save_best_model()\n",
    "            # Set the new maximum\n",
    "            self.model.best_iou_assign_op.eval(session=self.sess,\n",
    "                                               feed_dict={self.model.best_iou_input: mean_iou})\n",
    "        else:\n",
    "            print(\"hmm not the best validation epoch :/..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def test(self, pkl=False):\n",
    "        print(\"Testing mode will begin NOW..\")\n",
    "\n",
    "        # load the best model checkpoint to test on it\n",
    "        if not pkl:\n",
    "            self.load_best_model()\n",
    "\n",
    "        # init tqdm and get the epoch value\n",
    "        tt = tqdm(range(self.test_data_len))\n",
    "        # naming = np.load(self.args.data_dir + 'names_train.npy')\n",
    "\n",
    "        # init acc and loss lists\n",
    "        acc_list = []\n",
    "        img_list = []\n",
    "\n",
    "\n",
    "        # reset metrics\n",
    "        self.metrics.reset()\n",
    "\n",
    "        # loop by the number of iterations\n",
    "        for _ in tt:\n",
    "            # load mini_batches\n",
    "\n",
    "\n",
    "\n",
    "            feed_dict = {self.test_model.x_pl: x_batch,\n",
    "                         self.test_model.y_pl: y_batch,\n",
    "                         self.test_model.is_training: False\n",
    "                         }\n",
    "\n",
    "            # run the feed_forward\n",
    "            if self.args.data_mode == 'test_v2':\n",
    "                out_argmax, acc = self.sess.run(\n",
    "                    [self.test_model.out_argmax, self.test_model.accuracy],\n",
    "                    feed_dict=feed_dict)\n",
    "            else:\n",
    "                out_argmax, acc, segmented_imgs = self.sess.run(\n",
    "                    [self.test_model.out_argmax, self.test_model.accuracy,\n",
    "                     # self.test_model.merged_summaries, self.test_model.segmented_summary],\n",
    "                     self.test_model.segmented_summary],\n",
    "                    feed_dict=feed_dict)\n",
    "\n",
    "            if pkl:\n",
    "                out_argmax[0] = self.linknet_postprocess(out_argmax[0])\n",
    "                segmented_imgs = decode_labels(out_argmax, 20)\n",
    "\n",
    "            if self.args.data_mode == 'test':\n",
    "                plt.imsave(self.args.out_dir + 'imgs/' + 'test_' + str(cur_iteration) + '.png', segmented_imgs[0])\n",
    "\n",
    "            # log loss and acc\n",
    "            acc_list += [acc]\n",
    "\n",
    "            # log metrics\n",
    "            if self.args.random_cropping:\n",
    "                y1 = np.expand_dims(y_batch[0, :, :512], axis=0)\n",
    "                y2 = np.expand_dims(y_batch[0, :, 512:], axis=0)\n",
    "                y_batch = np.concatenate((y1, y2), axis=0)\n",
    "                self.metrics.update_metrics(out_argmax, y_batch, 0, 0)\n",
    "            else:\n",
    "                self.metrics.update_metrics(out_argmax[0], y_batch[0], 0, 0)\n",
    "\n",
    "        # mean over batches\n",
    "        total_loss = 0\n",
    "        total_acc = np.mean(acc_list)\n",
    "        mean_iou = self.metrics.compute_final_metrics(self.test_data_len)\n",
    "\n",
    "        # print in console\n",
    "        tt.close()\n",
    "        print(\"Here the statistics\")\n",
    "        print(\"Total_loss: \" + str(total_loss))\n",
    "        print(\"Total_acc: \" + str(total_acc)[:6])\n",
    "        print(\"mean_iou: \" + str(mean_iou))\n",
    "\n",
    "        print(\"Plotting imgs\")\n",
    "        for i in range(len(img_list)):\n",
    "            plt.imsave(self.args.imgs_dir + 'test_' + str(i) + '.png', img_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def test_eval(self, pkl=False):\n",
    "        print(\"Testing mode will begin NOW..\")\n",
    "\n",
    "        # load the best model checkpoint to test on it\n",
    "        if not pkl:\n",
    "            self.load_best_model()\n",
    "\n",
    "        # init tqdm and get the epoch value\n",
    "        tt = tqdm(range(self.test_data_len))\n",
    "\n",
    "\n",
    "        # loop by the number of iterations\n",
    "        for _ in tt:\n",
    "\n",
    "            # Feed this variables to the network\n",
    "            if self.args.random_cropping:\n",
    "                feed_dict = {self.test_model.x_pl_before: x_batch,\n",
    "                             self.test_model.is_training: False,\n",
    "                             }\n",
    "            else:\n",
    "                feed_dict = {self.test_model.x_pl: x_batch,\n",
    "                             self.test_model.is_training: False\n",
    "                             }\n",
    "\n",
    "            # run the feed_forward\n",
    "            out_argmax, segmented_imgs = self.sess.run(\n",
    "                [self.test_model.out_argmax,\n",
    "                 self.test_model.segmented_summary],\n",
    "                feed_dict=feed_dict)\n",
    "\n",
    "            # Colored results for visualization\n",
    "            #colored_save_path = self.args.out_dir + 'imgs/' + str(self.names_mapper['Y'][idx])\n",
    "            #if not os.path.exists(os.path.dirname(colored_save_path)):\n",
    "            #    os.makedirs(os.path.dirname(colored_save_path))\n",
    "            #plt.imsave(colored_save_path, segmented_imgs[0])\n",
    "\n",
    "            # Results for official evaluation\n",
    "            #save_path = self.args.out_dir + 'results/' + str(self.names_mapper['Y'][idx])\n",
    "            #if not os.path.exists(os.path.dirname(save_path)):\n",
    "            #    os.makedirs(os.path.dirname(save_path))\n",
    "            #output = postprocess(out_argmax[0])\n",
    "            #misc.imsave(save_path, misc.imresize(output, [1024, 2048], 'nearest'))\n",
    "\n",
    "\n",
    "        # print in console\n",
    "        tt.close()\n",
    "\n",
    "  \n",
    "    def finalize(self):\n",
    "        self.reporter.finalize()\n",
    "        self.summary_writer.close()\n",
    "        self.save_model()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
